{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Visualization Experiments\n",
    "\n",
    "Visualizing the sample images from the [Kaggle competition](https://www.kaggle.com/c/diabetic-retinopathy-detection/data).\n",
    "\n",
    "One [participant](https://github.com/hoytak/diabetic-retinopathy-code) pre-processed the images using ImageMagick. I've adopted his ideas for pre-processing, and added a few of my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import typing\n",
    "\n",
    "from os.path import join, exists, isdir, isfile, split\n",
    "\n",
    "import numpy as np\n",
    "from PIL.Image import fromarray\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.feature import canny\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = imread('sample/10_left.jpeg')\n",
    "im1 = imread('sample/10_left_conv.jpeg')\n",
    "im2 = imread('sample/10_left_conv_2.jpeg')\n",
    "im_512 = imread('sample/10_left_512_conv.jpeg')\n",
    "msg = 'Image 10 {}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image processing of the sample files\n",
    "\n",
    "Let's look at the original image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,20))\n",
    "ax.imshow(im)\n",
    "ax.set_title(msg.format('Unprocessed'), y=1.05)\n",
    "ax.xaxis.tick_top()\n",
    "plt.imshow(im);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scaled to $256\\times256$\n",
    "\n",
    "Now let's look at two processed images. I used the ```convert``` command-line program that comes with ImageMagick.\n",
    "\n",
    "```bash\n",
    "convert -fuzz 10% -trim +repage -resize 256x256 -gravity center -background black -extent 256x256 -equalize 10_left.jpeg 10_left_conv.jpeg\n",
    "```\n",
    "\n",
    "Recall that the images are a tensor of size ```(3168, 4752, 3)```, for example. The data structure is a tensor since it has a third dimension, the *channel*, which is red, green, or blue. For each channel, the matrix has entries from 0 to 255, indicating the color.\n",
    "\n",
    "The ```fuzz``` option has the effect that colors within this distance are considered equal.\n",
    "\n",
    "The black border has also been stripped, and the image size is scaled to $256\\times256$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(15,15))\n",
    "ax[0].imshow(im1);\n",
    "ax[0].set_title(msg.format('\\nprocessed with \"-fuzz 10%\"'), y=1.05)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[1].imshow(im2);\n",
    "ax[1].set_title(msg.format('\\nprocessed with \"-fuzz 2%\"'), y=1.05)\n",
    "ax[1].xaxis.tick_top()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, but let's compare each processed image to the unprocessed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(15,15))\n",
    "ax[0].imshow(im);\n",
    "ax[0].set_title(msg.format('\\nunprocessed'), y=1.05)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].add_artist(patches.Rectangle((2000, 2000), 2000, 1000, alpha=2, fill=False, edgecolor='magenta'))\n",
    "ax[1].imshow(im1);\n",
    "ax[1].set_title(msg.format('\\nprocessed with \"-fuzz 10%\"'), y=1.05)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].add_artist(patches.Rectangle((150, 200), 50, 50, alpha=2, fill=False,\n",
    "                                  edgecolor='magenta'))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the obvious size difference, we can see the blood vessels are brighter in the processed image, and we can also see a blood vessel in the lower right of the processed image that doesn't appear in the original. Also, the image overall is a brighter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(15,15))\n",
    "ax[0].imshow(im);\n",
    "ax[0].set_title(msg.format('\\nunprocessed'), y=1.05)\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].add_artist(patches.Rectangle((2000, 2000), 2000, 1000, alpha=2, fill=False, edgecolor='magenta'))\n",
    "ax[1].imshow(im2);\n",
    "ax[1].set_title(msg.format('\\nprocessed with \"-fuzz 2%\"'), y=1.05)\n",
    "ax[1].xaxis.tick_top()\n",
    "ax[1].add_artist(patches.Rectangle((150, 200), 50, 50, alpha=2, fill=False,\n",
    "                                  edgecolor='magenta'))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not seem to be much difference between 10% and 2%.\n",
    "\n",
    "### Rescaling the Image to $512 \\times 512$\n",
    "\n",
    "The image is bigger, of course, but it's also more expensive to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,20))\n",
    "ax.imshow(im_512)\n",
    "ax.set_title(msg.format('processed \"fuzz 10%\" 512x512'), y=1.05)\n",
    "ax.xaxis.tick_top()\n",
    "plt.imshow(im_512);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing All the Samples\n",
    "\n",
    "We can see all the sample images using the following code. Just run\n",
    "\n",
    "```python\n",
    "show_eyes()\n",
    "```\n",
    "\n",
    "There are several obvious things here.\n",
    "\n",
    "1. Some images do not have a notch, so they may be inverted.\n",
    "2. Some images may be clipped at the top or bottom, or left or right.\n",
    "3. An image may be blurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_left_right(i: int, as_grey: bool=False) -> typing.Tuple[np.ndarray, np.ndarray]:\n",
    "    left_file_name = join('sample', '{}_left.jpeg'.format(i))\n",
    "    right_file_name = join('sample', '{}_right.jpeg'.format(i))\n",
    "    im_l = imread(left_file_name)\n",
    "    im_r = imread(right_file_name)\n",
    "    if as_grey:\n",
    "        return rgb2gray(im_l), rgb2gray(im_r)\n",
    "    return im_l, im_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def side_by_side(im_l, im_r, cmap=None) -> None:\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(20,10))\n",
    "    ax[0].imshow(im_l, cmap=cmap)\n",
    "    ax[0].set_title('Left eye', y=1.05)\n",
    "    ax[0].xaxis.tick_top()\n",
    "    ax[1].imshow(im_r, cmap=cmap)\n",
    "    ax[1].set_title('Right eye', y=1.05)\n",
    "    ax[1].xaxis.tick_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_eyes() -> None:\n",
    "    img_idx = [10, 13, 15, 16, 17]\n",
    "    for i in img_idx:\n",
    "        im_l, im_r = load_left_right(i)\n",
    "        side_by_side(im_l, im_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_eyes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the Channels\n",
    "\n",
    "Let's take a look at each channel of the unprocessed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,20))\n",
    "ax.imshow(im[:, :, 0])\n",
    "ax.set_title(msg.format('Unprocessed red channel'), y=1.05)\n",
    "ax.xaxis.tick_top()\n",
    "plt.imshow(im[:, :, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,20))\n",
    "ax.imshow(im[:, :, 1])\n",
    "ax.set_title(msg.format('Unprocessed green channel'), y=1.05)\n",
    "ax.xaxis.tick_top()\n",
    "plt.imshow(im[:, :, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20,20))\n",
    "ax.imshow(im[:, :, 2])\n",
    "ax.set_title(msg.format('Unprocessed blue channel'), y=1.05)\n",
    "ax.xaxis.tick_top()\n",
    "plt.imshow(im[:, :, 2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Edge Detection\n",
    "\n",
    "Let's use the [Canny edge detection algorithm](https://en.wikipedia.org/wiki/Canny_edge_detector) to see what we get. In this case, it's easier to work with grayscale images to find the boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im_l, im_r = load_left_right(10, as_grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_by_side(im_l, im_r, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_10_edges = canny(im_l)\n",
    "fill_left_10 = ndi.binary_fill_holes(left_10_edges)\n",
    "right_10_edges = canny(im_r)\n",
    "fill_right_10 = ndi.binary_fill_holes(right_10_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny edge detection works well in this situation, at least for this example. Of course, we need to examine all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_by_side(fill_left_10, fill_right_10, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_10_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
